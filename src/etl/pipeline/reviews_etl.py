# File: pipeline/reviews_etl.py

"""
Module pour ex√©cuter l'ETL des avis Trustpilot (extraction, transformation, sauvegarde et chargement).

Ce module orchestre l'ensemble du processus ETL pour les avis Trustpilot : 
1. Extraction des avis depuis Trustpilot.
2. Transformation des donn√©es brutes en documents adapt√©s pour Elasticsearch.
3. Sauvegarde des donn√©es transform√©es au format JSONL.
4. Chargement des donn√©es dans Elasticsearch via une insertion en bulk.

Le processus peut √™tre configur√© pour ex√©cuter uniquement certaines √©tapes selon les besoins.
"""

import asyncio
from typing import List, Dict
from loguru import logger
from extract.reviews_scraper import get_reviews_from_trustpilot
from transform.transform_reviews import transform_reviews_for_elasticsearch
from load.elasticsearch_bulk_loader import load_reviews_to_elasticsearch_bulk
from utils.files_utils import FileUtils


def run_reviews_etl(
    max_pages: int,
    do_extract: bool = True,
    do_transform: bool = True,
    do_save: bool = True,
    do_load: bool = True
) -> None:
    """
    Lance le pipeline ETL complet des avis Trustpilot avec des options pour ex√©cuter chaque √©tape.

    Ce pipeline est constitu√© de plusieurs √©tapes : extraction, transformation, sauvegarde et chargement.
    Chaque √©tape peut √™tre activ√©e ou d√©sactiv√©e en fonction des besoins via les param√®tres 'do_extract',
    'do_transform', 'do_save', et 'do_load'.

    Param√®tres:
    -----------
    max_pages : int, optionnel
        Le nombre maximal de pages d'avis √† extraire depuis Trustpilot. Par d√©faut, 1.

    do_extract : bool, optionnel
        Si 'True', l'extraction des avis depuis Trustpilot est effectu√©e. Par d√©faut, 'True'.

    do_transform : bool, optionnel
        Si 'True', les avis extraits sont transform√©s en documents compatibles avec Elasticsearch. Par d√©faut, 'True'.

    do_save : bool, optionnel
        Si 'True', les donn√©es transform√©es sont sauvegard√©es au format JSONL. Par d√©faut, 'True'.

    do_load : bool, optionnel
        Si 'True', les documents transform√©s sont charg√©s dans Elasticsearch via l'API 'bulk'. Par d√©faut, 'False'.

    L√®ve:
    -----
    Exception
        Si une erreur se produit √† n'importe quelle √©tape du pipeline (extraction, transformation, sauvegarde, chargement).
    """
    logger.info(f"üöÄ D√©marrage du pipeline ETL Reviews (pages={max_pages})")

    extract_raw: List[Dict] = []
    transform_docs: List[Dict] = []

    # ---- Extraction ----
    if do_extract:
        try:
            logger.info("[1/4] Extraction des avis...")
            extract_raw = asyncio.run(
                get_reviews_from_trustpilot(max_pages=max_pages))

            # Sauvegarde via FileUtils
            FileUtils.save_to_json(extract_raw, "extract_raw")

            logger.success(
                f"Extraction termin√©e : {len(extract_raw)} reviews r√©cup√©r√©es")
        except Exception as e:
            logger.exception(f"‚ùå Erreur lors de l'extraction : {e}")

    # ---- Transformation ----
    if do_transform:
        try:
            if not extract_raw:
                logger.warning(
                    "‚ö†Ô∏è Aucune donn√©e brute trouv√©e, tentative de charger dernier JSON...")
                extract_raw = FileUtils.load_last_jsonl("data")
                if not extract_raw:
                    raise ValueError("Aucune donn√©e √† transformer")

            logger.info("[2/4] Transformation des avis...")
            transform_docs = transform_reviews_for_elasticsearch(extract_raw)
            logger.success(
                f"Transformation termin√©e : {len(transform_docs)} documents pr√™ts pour Elasticsearch")
        except Exception as e:
            logger.exception(f"‚ùå Erreur lors de la transformation : {e}")

    # ---- Sauvegarde JSONL ----
    if do_save:
        try:
            if not transform_docs:
                logger.warning(
                    "‚ö†Ô∏è Aucun document transform√© trouv√©, tentative de charger dernier JSON...")
                transform_docs = FileUtils.load_last_jsonl("data")
                if not transform_docs:
                    raise ValueError("Aucune donn√©e √† sauvegarder")

            logger.info("[3/4] Sauvegarde en JSONL...")
            jsonl_path = FileUtils.save_to_jsonl(transform_docs, "reviews")
            logger.info(f"üíæ Donn√©es sauvegard√©es : {jsonl_path}")
        except Exception as e:
            logger.exception(f"‚ùå Erreur lors de la sauvegarde JSONL : {e}")

    # ---- Chargement Elasticsearch ----
    if do_load:
        try:
            if not transform_docs:
                logger.warning(
                    "‚ö†Ô∏è Aucun document trouv√©, tentative de charger dernier JSON...")
                transform_docs = FileUtils.load_last_jsonl("data")
                if not transform_docs:
                    raise ValueError(
                        "Aucun document √† charger dans Elasticsearch")

            logger.info("[4/4] Chargement vers Elasticsearch...")
            load_reviews_to_elasticsearch_bulk(transform_docs, index="reviews")
            logger.success("Chargement Elasticsearch termin√©")
        except Exception as e:
            logger.exception(
                f"‚ùå Erreur lors du chargement Elasticsearch : {e}")
