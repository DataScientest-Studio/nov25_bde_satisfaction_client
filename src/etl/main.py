# File: main.py

"""
Main script
-----------
Ex√©cution du pipeline ETL pour r√©cup√©rer les avis Trustpilot, avec possibilit√© de d√©finir le nombre de pages √† scraper.

Ce script permet de lancer un pipeline ETL complet pour r√©cup√©rer les avis des entreprises sur Trustpilot. 
Le nombre de pages √† scraper peut √™tre sp√©cifi√© via la ligne de commande.

Le pipeline ETL inclut les √©tapes suivantes :
1. Extraction des avis depuis Trustpilot.
2. Transformation des avis pour les rendre compatibles avec Elasticsearch.
3. Sauvegarde des donn√©es en format JSONL.
4. Chargement des donn√©es dans Elasticsearch.

Usage :
------
python main.py --pages <nombre_de_pages>
"""
import argparse
from pipeline.reviews_etl import run_reviews_etl
from loguru import logger


def run_pipeline(pages: int) -> None:
    """
    Lance le pipeline ETL pour r√©cup√©rer les avis Trustpilot et effectuer les √©tapes d'extraction, 
    transformation, sauvegarde et chargement.

    Cette fonction appelle le pipeline ETL avec le nombre de pages sp√©cifi√© √† scraper.

    Parameters
    ----------
    pages : int
        Nombre de pages √† r√©cup√©rer par entreprise. Cette valeur est utilis√©e pour d√©finir la quantit√© de donn√©es √† scraper 
        pour chaque entreprise.
    
    L√®ve
    -----
    Exception
        Si une erreur se produit lors de l'ex√©cution du pipeline ETL (par exemple, une erreur lors de l'extraction, 
        transformation, sauvegarde ou chargement des donn√©es).
    """
    logger.info(f"üöÄ Ex√©cution du pipeline ETL (pages = {pages})")
    run_reviews_etl(max_pages=pages)


if __name__ == "__main__":
    # Parsing des arguments de ligne de commande
    parser = argparse.ArgumentParser(description="Lancer le pipeline ETL Trustpilot")
    parser.add_argument("--pages", type=int, default=10, help="Nombre de pages d'avis √† r√©cup√©rer")
    
    # R√©cup√©ration des arguments
    args = parser.parse_args()

    # Lancement du pipeline avec le nombre de pages sp√©cifi√©
    run_pipeline(args.pages)
